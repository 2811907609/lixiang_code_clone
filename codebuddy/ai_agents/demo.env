
# 模型配置示例文件
# 复制此文件为 local.env 并根据实际情况修改配置
# 注意

# 通用LLM配置（向后兼容）
export LLM_API_BASE="https://portal-k8s-prod.ep.chehejia.com/api/copilot/codefactory/bailian-deepseek-v3/v1"
export LLM_API_KEY="your_api_key_here"

# 强大模型配置 - 用于复杂任务（代码生成、复杂推理等）
export POWERFUL_MODEL="openai/deepseek-v3"
export POWERFUL_MODEL_TEMPERATURE="0.2"
export POWERFUL_MODEL_MAX_TOKENS="8192"
export POWERFUL_MODEL_TIMEOUT="300"

# 快速模型配置 - 用于简单任务（意图识别、分类等）
export FAST_MODEL="openai/gpt-4o-mini"
export FAST_MODEL_TEMPERATURE="0.1"
export FAST_MODEL_MAX_TOKENS="1024"
export FAST_MODEL_TIMEOUT="30"

# 摘要模型配置 - 专门用于文本摘要
export SUMMARY_MODEL="openai/gpt-4o-mini"
export SUMMARY_MODEL_TEMPERATURE="0.0"
export SUMMARY_MODEL_MAX_TOKENS="2048"
export SUMMARY_MODEL_TIMEOUT="60"

# 其他配置
export PORTAL_BASE_URL="https://portal-k8s-staging.ep.chehejia.com/api/v2"
export PORTAL_TOKEN=""

# 说明：
# 1. 如果某个特定模型的API配置为空，系统会回退到通用LLM配置
# 2. 可以为不同模型配置不同的API端点和密钥
# 3. 支持的任务类型：
#    - intent_classification: 意图识别 -> 快速模型
#    - code_generation: 代码生成 -> 强大模型
#    - summarization: 文本摘要 -> 摘要模型
#    - classification: 分类任务 -> 快速模型
#    - complex_reasoning: 复杂推理 -> 强大模型

# Codedoggy benchmark 配置
export CODEDOGGY_CONFIG=""
export CODEDOGGY_LANGFUSE_PRIVATE_KEY=""
export CODEDOGGY_LANGFUSE_PUBLIC_KEY=""
export CODEDOGGY_BENCHMARK_OUTPUT_DIR="/home/congziqi/code-complete/codebuddy/ai_agents"
export CODEDOGGY_QUICK_BENCHMARK="true"
export CODEDOGGY_BENCHMARK_MODEL="bailian-qwen3-coder-plus"
